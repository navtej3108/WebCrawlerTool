# Web Crawler Tool

## Overview

The **Web Crawler Tool** is a user-friendly Python-based application designed to extract query parameters from URLs and save the results in various formats. It provides a graphical interface for ease of use, enabling users to analyze websites without needing prior programming experience.

---

## Features

- **Add Multiple URLs**: Input multiple URLs to be crawled.
- **Extract Query Parameters**: Automatically extract query parameters from links within the specified domain.
- **Save Results**: Export the crawled data in **HTML**, **Excel**, or **Text** formats.
- **GUI Interface**: A simple and intuitive graphical user interface powered by Tkinter.
- **Error Handling**: Displays appropriate error messages for invalid URLs or network issues.

---

## Installation

### Prerequisites

1. Ensure **Python 3.8+** is installed on your system.
   - Download Python: [https://www.python.org/downloads/](https://www.python.org/downloads/)
2. Install the required Python libraries by running:
   "pip install -r requirements.txt"

### Steps

1. Clone the repository:
   "git clone https://github.com/navtej3108/WebCrawlerTool.git"
   
3. Navigate to the project directory:
   "cd WebCrawlerTool"
   
4. Install dependencies:
   "pip install -r requirements.txt"

5. Run the application:
   "python main.py"

---

## How to Use

1. Launch the application by running `python main.py`.
2. Use the **"Add URL"** button to input one or more URLs.
3. Click **"Start Crawling"** to begin the extraction process.
4. Choose a save option (HTML, Excel, or Text) from the new window that appears.
5. Your results will be saved in the project directory.

---

## Applications

- **SEO Analysis**: Extract parameters from URLs to analyze website structure.
- **Web Scraping**: Simplifies extracting information from webpages.
- **Data Collection**: Useful for research and data gathering.

---

## Supported Platforms

- **Windows 10/11**
- **macOS 10.14 (Mojave) or later**
- **Linux (Ubuntu and other distributions)**

---

## Repository

Find the complete source code here: **[Web Crawler Tool Repository](https://github.com/navtej3108/WebCrawlerTool)**

---

## Contributing

We welcome contributions! If you have suggestions or find bugs, feel free to open an issue or submit a pull request.

---

## License

This project is licensed under the MIT License.

---

## Contact

For any queries, reach out to **Navtej Pawan**.
**navtej3108@gmail.com**
**+919945754686**
